{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "# <center>Clustering Jerárquico</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenidos al Lab de Clustering Jerárquico con Python usando Scipy y el paquete Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Jerárquico - Aglomerativo\n",
    "\n",
    "Estaremos viendo la técnica de clustering, la cual es <b>Clustering Jerárquico Aglomerativo</b>. Recuerda que este enfoque, el aglomerativo, es un enfoque de abajo hacia arriba (bottom up). <br> <br>\n",
    "En este laboratorio, estaremos observando Clustering Aglomerativo, el cual es más popular que el Clustering Divisivo. <br> <br>\n",
    "También estaremos utilizando Enlace Completo como el Criterio de Enlaces. <br>\n",
    "<b> <i> NOTA: Puedes también intentar usar Enlaces Promedio donde el Enlace Completo sería usando, de esta forma, ¡verás la diferencia! </i> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import ndimage \n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import manifold, datasets \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.datasets.samples_generator import make_blobs \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generando los Datos Aleatorios\n",
    "Estaremos generando un conjunto de datos usando la clase <b>make_blobs</b>. <br> <br>\n",
    "Ingresa estos parámetros dentro de make_blobs:\n",
    "<ul>\n",
    "    <li> <b>n_samples</b>: Total de puntos divididos equitativamente entre los clusters. </li>\n",
    "    <ul> <li> Elegir un número entre 10-1500 </li> </ul>\n",
    "    <li> <b>centers</b>: El número de centros para generar, o las ubicaciones de centro fijas. </li>\n",
    "    <ul> <li> Elegir arreglas de coordenadas x,y para generar los centros. Tienes centros entre 1-10 (ej. centers=[[1,1], [2,5]]) </li> </ul>\n",
    "    <li> <b>cluster_std</b>: El desvío estándar de los clusters. Mientras más grande el número, más separados estarán los clusters.</li>\n",
    "    <ul> <li> Elegir un número entre 0.5-1.5 </li> </ul>\n",
    "</ul> <br>\n",
    "Guarda el resultado en <b>X1</b> y en <b>y1</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=50, centers=[[4,4], [-2, -1], [1, 1], [10,4]], cluster_std=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuj de la distribución de los puntos de los datos generados al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clustering Aglomerativo\n",
    "Comenzaremos haciendo el clustering de los datos aleatorios de los puntos que recién creamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b> La clase de Clustering Aglomerativo </b> necesita dos entradas:\n",
    "<ul>\n",
    "    <li> <b>n_clusters</b>: El número de clusters a formar y el número de centroides a generar. </li>\n",
    "    <ul> <li> Value will be: 4 </li> </ul>\n",
    "    <li> <b>linkage</b>: Criterio de Enlace a utilizar. El criterio de enlace determina la distancia a usar entre varias observaciones. El algoritmos agrupará en pares los clusters que minimizarán este criterio. </li>\n",
    "    <ul> \n",
    "        <li> El valor será: 'complete' </li> \n",
    "        <li> <b>Note</b>: Se recomienda también intentar todo con 'average' </li>\n",
    "    </ul>\n",
    "</ul> <br>\n",
    "Guarda el resultado en una variable llamada <b> agglom </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajusta el modelo con <b> X2 </b> y <b> y2 </b> a partir de los datos generados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agglom.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ejecuta el siguiente código para mostrar el clustering! <br>\n",
    "Recuerda leer el código y los comentarios para ganar más compresión de cómo trabaja el proceso de tramado/dibujo/ploteo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una figura de 6 pulgadas (aprox 15cm) por 4 pulgadas (aprox 10 cm).\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# Estas dos líneas de código se usan para reducir los puntos de datos,\n",
    "# porque sino los puntos de datos se verían muy separados y dispersos.\n",
    "\n",
    "# Crear un rango mínimo y máximo de X1.\n",
    "x_min, x_max = np.min(X1, axis=0), np.max(X1, axis=0)\n",
    "\n",
    "# Obtener la distancia promedio para X1.\n",
    "X1 = (X1 - x_min) / (x_max - x_min)\n",
    "\n",
    "# Este loop muestra todos los puntos de datos.\n",
    "for i in range(X1.shape[0]):\n",
    "    # Reemplaza los puntos de datos con su valor de cluster respectivo \n",
    "    # (ej. 0) está codificado con un mapa de colores (plt.cm.spectral)\n",
    "    plt.text(X1[i, 0], X1[i, 1], str(y1[i]),\n",
    "             color=plt.cm.nipy_spectral(agglom.labels_[i] / 10.),\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "    \n",
    "# Elimina los ticks x, ticks y, y los ejes x e y\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# Muestra el punteado de los datos originales ántes de clustering\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='.')\n",
    "# Muestra el punteo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dendograma Asociado al Clustering Aglomerativo Jerárquico\n",
    "Recuerda que una <b>matriz de distancia</b> contiene la <b> distancia de cada punto hacia cualquier otro punto del set de datos </b>. <br>\n",
    "Usa la función <b> distance_matrix, </b> la cual necesita <b>dos entradas</b>. Usa la Matriz de Confusión, <b> X2 </b> como ambas entradas para guardar la matriz de distancia en una variable de nombre <b> dist_matrix </b> <br> <br>\n",
    "Recuerda que los valores de sitancia son simétricos, con una diagonal de ceros. Esta es una forma de asegurarse que tu matriz es correcta. <br> (imprime dist_matrix para asegurarte que es correcta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(X1,X1) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la clase de <b> enlace </b> de la jerarquía, pasa los parámetros:\n",
    "<ul>\n",
    "    <li> La matriz de distancia </li>\n",
    "    <li> 'completa' se refiere al enlace completo </li>\n",
    "</ul> <br>\n",
    "Guarda el resultado en una variable de nombre <b> Z </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = hierarchy.linkage(dist_matrix, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clustering jerárquico se visualiza como un dendograma como se muestra en la siguiente celda. Cada agrupamiento se representa por una linea horizontal. La coordenada y de la linea horizontal se refiere a la similitud entre dos clusters que se agruparon, donde las ciudades se visualizan como clusters individuales. \n",
    "Moviéndose para arriba desde la capa inferior hacia el nodo superior,un dendograma nos permite reconstruir la historia de agrupamientos que resultaron en el clustering representado. \n",
    "\n",
    "Luego, guardaremos el dendograma en una variable llamada <b>dendro</b>. Al hacer esto, el dendograma también se dibujará.\n",
    "Utilizando la clase <b> dendrograma </b> de la jerarquía, se pasa en el parámetro:\n",
    "<ul> <li> Z </li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica\n",
    "Usamos enlace __completo__ en nuestro caso, lo cambiamos a enlace __promedio__ para ver cómo un dendograma cambia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe tu código aquí\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz doble click __aquí__ para ver la solución.\n",
    "\n",
    "<!-- Tu respuesta debajo:\n",
    "    \n",
    "Z = hierarchy.linkage(dist_matrix, 'average')\n",
    "dendro = hierarchy.dendrogram(Z)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Agrupando el dataset Vehículo\n",
    "\n",
    "Imagina que una fábrica de vehículos desarrolló prototipos para un nuevo vehículo. Antes de presentar el nuevo modelo, el fabracante quiere saber que vehículos existen en el mercado similares al prototipo--es decir, cómo se pueden agrupar los vehículos, qué grupo es el más parecido al del modelo y de esta forma, qué modelos competirán con el nuevo.\n",
    "\n",
    "Nuestro objetivo es utilizar métodos de clustering para encontrar los clusters más diferentes de vehículos. Se resumirán los vehículos actuales y ayudará al proceso de fabricación para tomar mejores decisiones para hacer modelos más simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar los datos\n",
    "Para descargar los datos, usaremos **`!wget`** desde IBM Object Storage.  \n",
    "__¿Sabías?__ Cuando se trata de Machine Learning, seguro trabajarás con grandes datasets (juego de datos). Entonces, ¿dónde podrás guardar esos datos? IBM ofrece una oportunidad única para las empresas, con 10 Tb de IBM Cloud Object Storage: [Registrate ahora gratuitamente](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O cars_clus.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "lets read dataset to see what features the manufacturer has collected about the existing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cars_clus.csv'\n",
    "\n",
    "#Read csv\n",
    "pdf = pd.read_csv(filename)\n",
    "print (\"Forma del set de datos: \", pdf.shape)\n",
    "\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los conjuntos de datos incluyen el precio en miles (price), tamaño de motor (engine_s), caballos de fuerza (horsepow), distancia entre ejes (wheelbas), ancho (width), largo (length), peso en vació (curb_wgt), capacidad de combustible (fuel_cap) y eficiencia de combustible (mpg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de Datos\n",
    "limpiemos el set de datos eliminando filas que tienen valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of dataset before cleaning: \", pdf.size)\n",
    "pdf[[ 'sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']].apply(pd.to_numeric, errors='coerce')\n",
    "pdf = pdf.dropna()\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "print (\"Forma del dataset luego de la limpieza: \", pdf.size)\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Característica\n",
    "Elijamos nuestro set en cuestión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = pdf[['engine_s',  'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización\n",
    "Ahora podemos normalizar el set. __MinMaxScaler__ transforma poniendo en escala a un rango. Por omisión es (0, 1). Es decir, las escalas dee estimación se traducen cada una individualmente de forma tal de quedar entre cero y uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = featureset.values #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "feature_mtx = min_max_scaler.fit_transform(x)\n",
    "feature_mtx [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando utilizando Scipy\n",
    "En esta parte, usaremos el paquete Scipy para agrupar el set de datos:  \n",
    "Primero, calcularemos la matriz de distancia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "leng = feature_mtx.shape[0]\n",
    "D = scipy.zeros([leng,leng])\n",
    "for i in range(leng):\n",
    "    for j in range(leng):\n",
    "        D[i,j] = scipy.spatial.distance.euclidean(feature_mtx[i], feature_mtx[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el clustering aglomerativo, en cada iteración, el algoritmo debe actualizar la matriz para refrejar la distancia del nuevo cluster formado a partir de los clusters restantes. \n",
    "Los métodos siguientes los soporta Scipy para calcular la distancia entre los recientementes formados clusters y para cada:\n",
    "    - simple\n",
    "    - completo\n",
    "    - promedio\n",
    "    - ponderado\n",
    "    - centroide\n",
    "    \n",
    "    \n",
    "Usaremos __completo__ para nuestro caso, pero si deseas puedes cambiar para ver los diferentes resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.cluster.hierarchy\n",
    "Z = hierarchy.linkage(D, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escencialmente, el clustering jerárquico no necesita de un número específico de clusters. Sin embargo, algunas aplicaciones que queremos una partición de clusters disjuntos como si fueran clustering tradicional.\n",
    "Por lo tanto podrás usar una linea en el medio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_d = 3\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, podrás determinar la cantidad de clusters directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "k = 5\n",
    "clusters = fcluster(Z, k, criterion='maxclust')\n",
    "clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se trazará el dendograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(18,50))\n",
    "def llf(id):\n",
    "    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])) )\n",
    "    \n",
    "dendro = hierarchy.dendrogram(Z,  leaf_label_func=llf, leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering utilizando scikit-learn\n",
    "Volvamos a construir el cluster, pero esta vez usando el paquete scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(feature_mtx,feature_mtx) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos usar la función 'AgglomerativeClustering' de la librería scikit-learn para agrupar el set de datos. Esta función hace un clustering jerárquico por medio de un enfoque de abajo hacia arriba (bottom up). El criterio de enlace determina la métrica utilizada para la estrategia de unificación:\n",
    "\n",
    "- Ward minimiza la suma de las diferencias cuadráticas dentro de todos los clusters. Es una enfoque minimizado y en este sentido se parece al la función de objetivo de k-medias pero está encarado con un enfoque jerárquico aglomerativo.\n",
    "- El Enlace máximo o completo, minimiza la distancia máxima entre las observaciones de pares de clusters.\n",
    "- El Enlace promedio minimiza el promedio de las distancias entre todas las observaciones de pares de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 6, linkage = 'complete')\n",
    "agglom.fit(feature_mtx)\n",
    "agglom.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agregar un nuevo campo a nuestro marco de datos para mostrar el cluster de cada fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['cluster_'] = agglom.labels_\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "n_clusters = max(agglom.labels_)+1\n",
    "colors = cm.rainbow(np.linspace(0, 1, n_clusters))\n",
    "cluster_labels = list(range(0, n_clusters))\n",
    "\n",
    "# Crear una figura de 6 pulgadas (aprox 15cm) por 4 pulgadas (aprox 10cm).\n",
    "plt.figure(figsize=(16,14))\n",
    "\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = pdf[pdf.cluster_ == label]\n",
    "    for i in subset.index:\n",
    "            plt.text(subset.horsepow[i], subset.mpg[i],str(subset['model'][i]), rotation=25) \n",
    "    plt.scatter(subset.horsepow, subset.mpg, s= subset.price*10, c=color, label='cluster'+str(label),alpha=0.5)\n",
    "#    plt.scatter(subset.horsepow, subset.mpg)\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, es una distribución de cada cluster utilizando una trama esparcida, pero no está muy claro dónde es el centroide de cada cluster. Es más, hay 2 tipos de vehículos en nuestro set de datos, \"truck\" (valor de 1 en la columna tipo) y \"car\" (valor 1 en la columna tipo). Asi que los usaremos para distinguir las clases y sumarizar el cluster. Primero contamos la cantidad de casos de cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.groupby(['cluster_','type'])['cluster_'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos examinar a las características de cada cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cars = pdf.groupby(['cluster_','type'])['horsepow','engine_s','mpg','price'].mean()\n",
    "agg_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Es obvio que tenemos 3 clusters principales donde están la mayoría de los vehículos en ellos.\n",
    "\n",
    "__Coches__:\n",
    "- Cluster 1: con algo mpg, y poco caballos de fuerza.\n",
    "- Cluster 2: con buenos mpg y caballos de fuerza, pero un precio más alto que el promedio.\n",
    "- Cluster 3: con bajo mpg, muchos caballos de fuerza y el precio más alto de todos.\n",
    "    \n",
    "    \n",
    "    \n",
    "__Camiones__:\n",
    "- Cluster 1: con el más alto mpg entre los camiones, y lo más bajo en caballos de fuerza y precio.\n",
    "- Cluster 2: con bajo mpg y media de caballos de fuerza, pero el precio más alto que el promedio.\n",
    "- Cluster 3: con bueno mpg y caballos de fuerza, bajo precio.\n",
    "\n",
    "\n",
    "Notar que no utilizamos __type__ , y __price__ de autos en el proceso de clustering, sino que utilizamos clustering Jerárquico para discriminar los clusters con una precisión bastante alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = agg_cars.loc[(label,),]\n",
    "    for i in subset.index:\n",
    "        plt.text(subset.loc[i][0]+5, subset.loc[i][2], 'type='+str(int(i)) + ', price='+str(int(subset.loc[i][3]))+'k')\n",
    "    plt.scatter(subset.horsepow, subset.mpg, s=subset.price*20, c=color, label='cluster'+str(label))\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Deseas aprender más?\n",
    "\n",
    "IBM SPSS Modeler es una plataforma para analytics que contiene varios algoritmos de machine learning. Fue diseñada para acercar inteligencia predictiva a las decisiones hechas por individuos, grupos, sistemas, toda la empresa. Un free trial está disponible a través de este curso en: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "Asi mismo, puedes utilizar Watson Studio para ejecutar estos notebooks más rápido y con datasets más grandes. Watson Studio es una solución en la nube lider de IBM's para científicos de datos, construída por científicos de datos. Con Jupyter notebooks, RStudio, Apache Spark y librerías conocidas pre instaladas en la nube, Watson Studio posibilita a los científicos de datos colaborar en sus proyectos sin tener que instalar nada. Sumate a la comunidad de usuarios Watson Studio hoy mismo por medio de una cuenta gratuita en [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### ¡Gracias por completar esta lección!\n",
    "\n",
    "Notebook creado por: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). Este lab y su código fuente fueron registrados bajo los términos de [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
